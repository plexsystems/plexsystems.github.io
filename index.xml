<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Plex Engineering</title><link>https://plexsystems.github.io/</link><description>Recent content on Plex Engineering</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 22 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://plexsystems.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Developing Versionless APIs with GraphQL</title><link>https://plexsystems.github.io/posts/developing-versionless-graphql-apis/</link><pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate><guid>https://plexsystems.github.io/posts/developing-versionless-graphql-apis/</guid><description>Many of the services that we write at Plex rely on REST (or REST-like) APIs. While REST APIs make sense for many of these services, it does not make sense for all of them. For some domains, such as EDI, that require many endpoints, performance, and maintenance concerns start to become a problem. Every API call is a round-trip from the client to the server, impacting the overall performance of the initial request.</description></item><item><title>Introducing Sinker: A tool to sync container images from one registry to another</title><link>https://plexsystems.github.io/posts/introducing-sinker/</link><pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate><guid>https://plexsystems.github.io/posts/introducing-sinker/</guid><description>At Plex, all container images in our environments are sourced from our internal container registries. While this gives us greater control over which images can and cannot be used in our environments, it poses a bigger problem. How can we leverage container images that are managed in the public cloud?
A common solution to this problem is to sync the public container image to your organization&amp;rsquo;s private registry by pulling down the image and then pushing it to your internal registry.</description></item><item><title>Testing Containers with Container Structure Test</title><link>https://plexsystems.github.io/posts/container-structure-test/</link><pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate><guid>https://plexsystems.github.io/posts/container-structure-test/</guid><description>It is no secret that when we are writing software, tests are a critical component to ensure the code actually does what we say it does. It is so critical that most languages come with testing frameworks. JavaScript has testing frameworks such as mocha and jasmine. Go ships with its own testing capabilities provided by the testing package. And while writing tests in these languages is an accepted standard practice, all too often we forget that there is more to getting an application onto production than the app itself.</description></item><item><title>Accelerated Feedback Loops when Developing for Kubernetes with Conftest</title><link>https://plexsystems.github.io/posts/kubernetes-policy-conftest/</link><pubDate>Sat, 23 May 2020 00:00:00 +0000</pubDate><guid>https://plexsystems.github.io/posts/kubernetes-policy-conftest/</guid><description>The feedback loop when deploying to Kubernetes can be quite slow. Not only does the YAML need to be syntactically correct, but we need to ask ourselves:
Is the API version of our resource definition compatible with the version of Kubernetes that it is being deployed to? Kubernetes is constantly evolving, and over time, deprecates older APIs in favor of newer ones. A deployment definition may successfully apply on one version of Kubernetes, but not another.</description></item><item><title>Deploying Atlantis for Azure DevOps onto Kubernetes</title><link>https://plexsystems.github.io/posts/deploying-infrastructure-azure/</link><pubDate>Sun, 05 Apr 2020 00:00:00 +0000</pubDate><guid>https://plexsystems.github.io/posts/deploying-infrastructure-azure/</guid><description>At Plex, our initial adoption of Terraform was relatively painless. There weren&amp;rsquo;t many teams writing infrastructure as code, and most of the changes that were being deployed through Terraform were new pieces of infrastructure that didn&amp;rsquo;t have any dependencies.
As the number of teams using Terraform and managing their own infrastructure grew, it became apparent that we needed to start putting some processes in place for a few reasons.
Collaboration was difficult In order for an engineer to verify their Terraform changes, they needed to be able to run terraform plan against live infrastructure.</description></item></channel></rss>